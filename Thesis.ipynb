{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1> Cuda verification </h1>",
   "id": "59300a61728d2dd1"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-01T13:08:15.282598Z",
     "start_time": "2025-08-01T13:08:15.237557Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 173,
   "source": [
    "import torch\n",
    "\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1>Augmentation pipeline </h1>",
   "id": "f4338befb71eb1a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T11:30:55.887641Z",
     "start_time": "2025-08-01T11:30:55.474800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "training_pipeline = A.Compose([\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.SquareSymmetry(p=0.5),\n",
    "    A.RandomCrop(height=180, width=180,  p=1.0),\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.RandomRain(slant_range=(-15,15), drop_length=15, drop_width=1, rain_type=\"default\", blur_value=7 ,p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=(-0.2, 0.2), p=0.3),\n",
    "    A.Rotate(limit=45, p=0.5),\n",
    "    A.GaussNoise(std_range=(0.1, 0.2), per_channel=True  ,p=0.5),\n",
    "    A.ColorJitter(brightness=(0.8, 1.1), contrast=(0.8, 1.1), saturation=(0.8, 1.1), hue=(-0.5, 0.5)),\n",
    "    A.OneOf([\n",
    "        A.CoarseDropout(num_holes_range=(1, 8), hole_height_range=(0.1, 0.25),\n",
    "                        hole_width_range=(0.1, 0.25), fill=0, p=0.5),\n",
    "        A.GridDropout(ratio=0.5, random_offset=True,  p=0.5)\n",
    "    ]),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "validation_pipeline = A.Compose([\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ],
   "id": "c5c5dfd54b31be52",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Data preparation</h2>",
   "id": "8c508484763306ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:47:01.813480Z",
     "start_time": "2025-08-01T13:47:01.803408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_image_datasets(source_dir, base_dir, split_ratios=(0.7, 0.2, 0.1)):\n",
    "\n",
    "     if not (0.999 < sum(split_ratios) < 1.001):\n",
    "         raise ValueError('split_ratios must sum to 1')\n",
    "\n",
    "     source_path = Path(source_dir)\n",
    "     base_path = Path(base_dir)\n",
    "\n",
    "     if not source_path.is_dir():\n",
    "         print(f'Source directory {source_path.name} does not exist')\n",
    "         return\n",
    "\n",
    "     train_path = base_path / 'train'\n",
    "     test_path = base_path / 'test'\n",
    "     val_path = base_path / 'val'\n",
    "\n",
    "     class_names = [d.name for d in source_path.iterdir() if d.is_dir()]\n",
    "\n",
    "     if not class_names:\n",
    "         print(f'Source directory {source_path.name} does not contain any class names')\n",
    "         return\n",
    "\n",
    "     for directory in [train_path, test_path, val_path]:\n",
    "         for class_name in class_names:\n",
    "             (directory / class_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "     for class_name in class_names:\n",
    "\n",
    "         class_source_path = source_path / class_name\n",
    "\n",
    "         files = [f for f in class_source_path.iterdir() if f.is_file()]\n",
    "\n",
    "         random.shuffle(files)\n",
    "\n",
    "         total_files = len(files)\n",
    "         train_end = int(total_files * split_ratios[0])\n",
    "         test_end = train_end + int(total_files * split_ratios[1])\n",
    "\n",
    "         split_data = {\n",
    "             'train': (files[:train_end], train_path),\n",
    "             'test': (files[train_end:test_end], test_path),\n",
    "             'val': (files[test_end:], val_path)\n",
    "         }\n",
    "\n",
    "         print(f\"Copying {class_name} to {base_path}\")\n",
    "\n",
    "         for split_name, (file_list, destination_path) in split_data.items():\n",
    "\n",
    "             dest_class_path = destination_path / class_name\n",
    "\n",
    "             for file_path in tqdm(file_list, desc=f'Copying {split_name} files'):\n",
    "\n",
    "                 shutil.copy2(file_path, dest_class_path / file_path.name)\n"
   ],
   "id": "3f61bebddba66303",
   "outputs": [],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T11:54:31.848252Z",
     "start_time": "2025-08-01T11:54:31.770691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from torchvision import datasets\n",
    "\n",
    "class CustomDataset(datasets.ImageFolder):\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        path, target = self.samples[index]\n",
    "\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "data = CustomDataset(root='dataset', transform=training_pipeline)\n",
    "\n",
    "# image, path = data[0]\n",
    "#\n",
    "# print(path)\n",
    "#\n",
    "# image = image.permute(1,2,0).numpy()\n",
    "#\n",
    "# image = (image * np\n",
    "#          .array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n",
    "# image = np.clip(image, 0, 1)\n",
    "# image = (image * 255).astype(np.uint8)\n",
    "#\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ],
   "id": "4165f31c2a079958",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2> Data splitting </h2>",
   "id": "638f3a60c11f293c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T13:46:06.517510Z",
     "start_time": "2025-08-01T13:45:25.320755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source_data_dir = r'C:\\Users\\LANCE\\OneDrive\\Desktop\\rice_pest\\Finalized_datasets'\n",
    "base_data_dir = r'C:\\Users\\LANCE\\OneDrive\\Desktop\\rice_pest\\dataset'\n",
    "\n",
    "if not source_data_dir or not base_data_dir:\n",
    "    raise ValueError('Source and base data directory not found')\n",
    "\n",
    "prepare_image_datasets(source_data_dir, base_data_dir, split_ratios=(0.7, 0.2, 0.1))\n"
   ],
   "id": "407974787d3ba3a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train files: 100%|██████████| 1362/1362 [00:09<00:00, 151.11it/s]\n",
      "Copying test files: 100%|██████████| 389/389 [00:02<00:00, 151.45it/s]\n",
      "Copying val files: 100%|██████████| 195/195 [00:01<00:00, 157.64it/s]\n",
      "Copying train files: 100%|██████████| 763/763 [00:05<00:00, 149.81it/s]\n",
      "Copying test files: 100%|██████████| 218/218 [00:01<00:00, 164.58it/s]\n",
      "Copying val files: 100%|██████████| 109/109 [00:00<00:00, 156.36it/s]\n",
      "Copying train files: 100%|██████████| 1204/1204 [00:07<00:00, 153.75it/s]\n",
      "Copying test files: 100%|██████████| 344/344 [00:02<00:00, 164.47it/s]\n",
      "Copying val files: 100%|██████████| 172/172 [00:01<00:00, 159.31it/s]\n",
      "Copying train files: 100%|██████████| 671/671 [00:04<00:00, 161.03it/s]\n",
      "Copying test files: 100%|██████████| 191/191 [00:01<00:00, 149.55it/s]\n",
      "Copying val files: 100%|██████████| 97/97 [00:00<00:00, 151.51it/s]\n",
      "Copying train files: 100%|██████████| 410/410 [00:02<00:00, 157.82it/s]\n",
      "Copying test files: 100%|██████████| 117/117 [00:00<00:00, 154.45it/s]\n",
      "Copying val files: 100%|██████████| 59/59 [00:00<00:00, 171.70it/s]\n"
     ]
    }
   ],
   "execution_count": 174
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2> Training functions and hyperparameters</h2>",
   "id": "dba860140f2d1e9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:07:52.628164Z",
     "start_time": "2025-08-03T14:07:52.620863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class LSoftmax(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features, number_of_classes, m=4):\n",
    "        super(LSoftmax, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.number_of_classes = number_of_classes\n",
    "        self.m = m\n",
    "\n",
    "        if m <= 1:\n",
    "            raise ValueError('m must be greater than 1')\n",
    "\n",
    "        # Initialization of weights through xavier uniform.\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(input_features, number_of_classes))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "\n",
    "    # Forward propagation\n",
    "    def forward(self, x, labels):\n",
    "\n",
    "        # normalization of weights and input vector features.\n",
    "        normalize_weight = F.normalize(self.weight, p=2, dim=1)\n",
    "        normalize_x = F.normalize(x, p=2, dim=1)\n",
    "\n",
    "        # Cosine similarity: perform DOT product multiplication between weights and input vectors.\n",
    "        cos_theta = F.linear(normalize_x, normalize_weight.t())\n",
    "        cos_theta = cos_theta.clamp(-1,1)\n",
    "\n",
    "        # Convert cosine similarity into actual angles.\n",
    "        theta = torch.acos(cos_theta)\n",
    "\n",
    "        # Gathered the correct classes as one vector and reshape it in to a 2d with one column.\n",
    "        target_theta = theta.gather(1, labels.view(-1,1))\n",
    "\n",
    "        # applies the margin to the correct classes\n",
    "        m_theta = self.m * target_theta\n",
    "        k = (m_theta / math.pi).floor()\n",
    "\n",
    "        # Compute the angular margin to get a new hard target score for prediction\n",
    "        psi_theta = ((-1)**k) * torch.cos(m_theta) - (2*k)\n",
    "\n",
    "        # Scattered the new values got from psi_theta to its corresponding classes\n",
    "        final_logits = cos_theta.scatter(1, labels.view(-1,1), psi_theta)\n",
    "\n",
    "        return final_logits\n"
   ],
   "id": "31a9a78b6df933f4",
   "outputs": [],
   "execution_count": 244
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T08:41:16.293249Z",
     "start_time": "2025-08-04T08:41:16.246386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t = torch.tensor([[1, 2, 3, 4],\n",
    "                  [5,6,7,8]])\n",
    "\n",
    "t.gather(1, torch.tensor())\n",
    "\n",
    "# t = torch.tensor([[1, 2, 3, 4],\n",
    "#                   [5,6,7,8]])\n",
    "#\n",
    "# print(t.view(-1,1))"
   ],
   "id": "eec42032231e0ff9",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[144]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m t = torch.tensor([[\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m, \u001B[32m3\u001B[39m, \u001B[32m4\u001B[39m],\n\u001B[32m      2\u001B[39m                   [\u001B[32m5\u001B[39m,\u001B[32m6\u001B[39m,\u001B[32m7\u001B[39m,\u001B[32m8\u001B[39m]])\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgather\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# t = torch.tensor([[1, 2, 3, 4],\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m#                   [5,6,7,8]])\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# \u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# print(t.view(-1,1))\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3> LSmax Test </h3>",
   "id": "8abca27bc20b3b89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:13:28.962845Z",
     "start_time": "2025-08-03T14:13:28.957393Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the output logits: torch.Size([4, 6])\n",
      "\n",
      "Output Logits Tensor (first 2 rows):\n",
      "[[-2.2175212  -0.46530092  0.4388179  -0.13423419  0.6960334   0.20117837]\n",
      " [ 0.06377348  0.31151363  0.52479124  0.12865415 -3.1037827   0.04310565]]\n"
     ]
    }
   ],
   "execution_count": 277,
   "source": [
    "NUM_FEATURES = 1280\n",
    "NUM_CLASSES = 6\n",
    "BATCH_SIZE = 4\n",
    "MARGIN = 4\n",
    "\n",
    "lsoftmax_layer = LSoftmax(\n",
    "    input_features=NUM_FEATURES,\n",
    "    number_of_classes=NUM_CLASSES,\n",
    "    m=MARGIN\n",
    ")\n",
    "\n",
    "dummy_features = torch.randn(BATCH_SIZE, NUM_FEATURES)\n",
    "dummy_labels = torch.randint(0, NUM_CLASSES, (BATCH_SIZE,))\n",
    "res = lsoftmax_layer(dummy_features, dummy_labels)\n",
    "\n",
    "print(\"Shape of the output logits:\", res.shape)\n",
    "print(\"\\nOutput Logits Tensor (first 2 rows):\")\n",
    "print(res.detach().numpy()[:2])"
   ],
   "id": "42f054b187673f6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T05:18:49.674229Z",
     "start_time": "2025-08-04T05:18:49.646369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class PestClassifierMobileNetV2(nn.Module):\n",
    "\n",
    "    def __init__(self,num_classes , margin):\n",
    "        super(PestClassifierMobileNetV2, self).__init__()\n",
    "\n",
    "        # get model\n",
    "        self.base_model = models.mobilenet_v2(weights='MobileNet_V2_Weights.IMAGENET1K_V2')\n",
    "\n",
    "        # Froze feature extraction layer to retain weights.\n",
    "        for params in self.base_model.parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "        # get number of features\n",
    "        num_filters = self.base_model.classifier[1].in_features\n",
    "\n",
    "        # Hyperparameter tuning: Instantiate LSoftmax as new customized final layer.\n",
    "        self.base_model.classifier[1] = LSoftmax(\n",
    "            input_features=num_filters,\n",
    "            number_of_classes=num_classes,\n",
    "            m=margin\n",
    "        )\n",
    "\n",
    "    # Forward propagation\n",
    "    def forward(self, x, labels=None):\n",
    "\n",
    "        if labels is None:\n",
    "            return self.base_model(x)\n",
    "\n",
    "        # Passed the features in feature extraction layer.\n",
    "        features = self.base_model.features(x)\n",
    "\n",
    "        # Adaptive average pooling: returns a 2d scaled vector features.\n",
    "        features = F.adaptive_avg_pool2d(features, (1,1)).reshape(features.shape[0], -1)\n",
    "\n",
    "        # Implementation of the LSoftmax through passing the feature vectors for classification.\n",
    "        logits = self.base_model.classifier[1](features)\n",
    "\n",
    "        # return the result logits\n",
    "        return logits\n"
   ],
   "id": "ec3d396b8b938549",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T17:06:57.775198Z",
     "start_time": "2025-08-04T17:06:57.763514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_test(model, optimizer, criterion, train_dataloader, test_dataloader, num_epoch, device):\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "\n",
    "        # Training phase\n",
    "        for data, labels in tqdm(train_dataloader, desc=f\"Train epoch: {epoch+1}\"):\n",
    "\n",
    "            data, target = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data, labels)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        training_loss = running_train_loss / len(train_dataloader)\n",
    "\n",
    "        # Testing phase\n",
    "\n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for inputs, labels in tqdm(test_dataloader, desc=f\"Test epoch: {epoch+1}\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                output_loss = model(inputs, labels)\n",
    "                loss = criterion(output_loss, labels)\n",
    "                running_test_loss += loss.item()\n",
    "\n",
    "                output_predictions = model(inputs, labels=None)\n",
    "                _, predicted = torch.max(output_predictions.data, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "        testing_loss = running_test_loss / len(test_dataloader)\n",
    "        accuracy = 100 * correct_predictions / total_samples\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epoch} | Train Loss: {training_loss} | Test Loss: {testing_loss} | Accuracy: {accuracy}')\n",
    "\n",
    "    print('Training done!')"
   ],
   "id": "ce2d84aa93514e4e",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T06:58:05.606637Z",
     "start_time": "2025-08-04T06:58:05.536213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = models.mobilenet_v2(weights='MobileNet_V2_Weights.IMAGENET1K_V2')\n",
    "\n",
    "# print(model.classifier[1])\n",
    "print(model.features)"
   ],
   "id": "70fc048993a81d19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2dNormActivation(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (4): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (9): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (12): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (13): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (15): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (17): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (18): Conv2dNormActivation(\n",
      "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T11:12:56.503471Z",
     "start_time": "2025-08-04T11:12:56.468555Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.features[0])",
   "id": "addb634cef4616cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T04:37:03.301934Z",
     "start_time": "2025-08-04T04:37:03.274456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(4, 1280, 1, 1)\n",
    "a.reshape(4, -1)"
   ],
   "id": "27a5d55f61892fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6195, -0.1782, -2.5715,  ...,  0.0331,  0.7603,  0.0035],\n",
       "        [-0.2862,  1.4578,  1.0089,  ...,  1.1253,  0.0103,  1.5974],\n",
       "        [-0.3662,  2.0849, -0.4080,  ..., -0.4553, -1.3057, -0.6453],\n",
       "        [ 1.8317, -1.2072,  0.1279,  ..., -0.2502, -2.0353,  0.0071]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T03:04:36.935884Z",
     "start_time": "2025-08-04T03:04:36.928884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "m = nn.AdaptiveAvgPool2d((5, 7))\n",
    "input = torch.randn(1, 64, 8, 9)\n",
    "output = m(input)\n",
    "# print(input)\n",
    "print(output)"
   ],
   "id": "72bac0fc4c1c0861",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2691,  0.9643,  0.8347,  ..., -0.1645, -0.1972, -0.2539],\n",
      "          [ 0.2757,  0.9418,  0.9279,  ...,  0.5813,  0.1480, -0.1334],\n",
      "          [ 0.0424,  0.0234, -0.4845,  ...,  0.5998, -0.1160,  0.5142],\n",
      "          [ 0.4355,  0.0480, -0.6159,  ...,  0.0204, -0.6934, -0.3013],\n",
      "          [ 0.2712,  0.3419, -0.3261,  ..., -0.7096, -0.8251, -0.5811]],\n",
      "\n",
      "         [[ 0.5099, -0.4436, -0.1795,  ...,  0.9180,  0.1221, -0.5859],\n",
      "          [ 0.2151, -0.2515, -0.0462,  ...,  0.3873,  0.2008, -0.3096],\n",
      "          [-0.2853, -0.7343, -0.6029,  ...,  0.3461,  1.0835,  0.1555],\n",
      "          [-0.5955, -0.3730,  0.0737,  ...,  0.0337,  0.1940, -0.0271],\n",
      "          [-0.3843, -0.3897, -0.2840,  ..., -0.3347, -0.0284, -0.2131]],\n",
      "\n",
      "         [[ 0.2297,  0.6255,  0.5641,  ..., -0.9883, -1.5511, -0.7901],\n",
      "          [ 0.3697,  0.2164,  0.4150,  ..., -0.0471, -0.8920, -0.4873],\n",
      "          [ 0.2315,  0.2039,  0.3022,  ...,  0.9991,  0.1681,  0.1191],\n",
      "          [-0.1260,  0.3516,  0.5540,  ...,  0.0779, -0.3429, -0.2304],\n",
      "          [-0.5682,  0.1579, -0.0344,  ..., -0.0618, -0.2110,  0.1175]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6150,  0.6456, -0.2932,  ...,  0.8546,  0.7936,  0.1099],\n",
      "          [ 0.2835,  0.2893,  0.3964,  ...,  0.0333,  0.3866,  0.1173],\n",
      "          [ 0.1400, -0.5249,  0.4299,  ..., -0.2286,  0.0738, -0.7064],\n",
      "          [-0.0273, -0.6368,  0.0249,  ...,  0.5992,  0.4649, -0.7985],\n",
      "          [-0.1805, -0.5087, -0.4180,  ...,  0.1171,  0.1937, -0.6574]],\n",
      "\n",
      "         [[-0.5340, -0.5393, -0.1845,  ..., -0.3295, -0.2682, -0.9194],\n",
      "          [-0.7766, -0.6549, -0.3514,  ...,  0.3879,  0.0888, -0.5115],\n",
      "          [ 0.5817,  0.4015, -0.4562,  ...,  0.3205,  0.4115,  0.4215],\n",
      "          [ 0.1233, -0.1064, -0.2970,  ...,  0.5230,  0.6890,  0.1809],\n",
      "          [ 0.1536, -0.4041,  0.7407,  ..., -0.4805, -0.5290, -0.3725]],\n",
      "\n",
      "         [[-0.0880, -0.5350, -0.6104,  ..., -0.0955,  0.3950, -0.4115],\n",
      "          [-0.1270, -0.1667, -0.0691,  ...,  0.3164,  0.8346,  0.2359],\n",
      "          [-0.0628,  0.6373,  0.4045,  ...,  0.5000,  0.5107, -0.0409],\n",
      "          [-0.2748, -0.1589, -0.2421,  ...,  0.5904,  0.0789, -0.2165],\n",
      "          [-0.2584,  0.0901, -0.1130,  ..., -0.0214,  0.6294,  0.6648]]]])\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T14:09:53.123027Z",
     "start_time": "2025-08-04T14:09:53.008120Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4b239c3d1796a221",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f\n"
     ]
    }
   ],
   "execution_count": 151
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
