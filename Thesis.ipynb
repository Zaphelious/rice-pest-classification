{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1> Cuda verification </h1>",
   "id": "59300a61728d2dd1"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-01T13:08:15.282598Z",
     "start_time": "2025-08-01T13:08:15.237557Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 173,
   "source": [
    "import torch\n",
    "\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1>Augmentation pipeline </h1>",
   "id": "f4338befb71eb1a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T06:06:50.257645Z",
     "start_time": "2025-08-06T06:06:50.124030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "training_pipeline = A.Compose([\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.SquareSymmetry(p=0.5),\n",
    "    A.RandomCrop(height=180, width=180,  p=1.0),\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.RandomRain(slant_range=(-15,15), drop_length=15, drop_width=1, rain_type=\"default\", blur_value=7 ,p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=(-0.2, 0.2), p=0.3),\n",
    "    A.Rotate(limit=45, p=0.4),\n",
    "    A.GaussNoise(std_range=(0.1, 0.2), per_channel=True  ,p=0.5),\n",
    "    A.ColorJitter(brightness=(0.8, 1.1), contrast=(0.8, 1.1), saturation=(0.8, 1.1), hue=(-0.5, 0.5)),\n",
    "    A.OneOf([\n",
    "        A.CoarseDropout(num_holes_range=(1, 8), hole_height_range=(0.1, 0.25),\n",
    "                        hole_width_range=(0.1, 0.25), fill=0, p=0.5),\n",
    "        A.GridDropout(ratio=0.5, random_offset=True,  p=0.5)\n",
    "    ]),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "validation_pipeline = A.Compose([\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ],
   "id": "c5c5dfd54b31be52",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Data preparation</h2>",
   "id": "8c508484763306ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T06:09:28.288302Z",
     "start_time": "2025-08-06T06:09:28.281349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_image_datasets(source_dir, base_dir, split_ratios=(0.7, 0.2, 0.1)):\n",
    "\n",
    "     if not (0.999 < sum(split_ratios) < 1.001):\n",
    "             raise ValueError('split_ratios must sum to 1')\n",
    "\n",
    "     source_path = Path(source_dir)\n",
    "     base_path = Path(base_dir)\n",
    "\n",
    "     if not source_path.is_dir():\n",
    "         print(f'Source directory {source_path.name} does not exist')\n",
    "         return\n",
    "\n",
    "     train_path = base_path / 'train'\n",
    "     test_path = base_path / 'test'\n",
    "     val_path = base_path / 'val'\n",
    "\n",
    "     class_names = [d.name for d in source_path.iterdir() if d.is_dir()]\n",
    "\n",
    "     if not class_names:\n",
    "         print(f'Source directory {source_path.name} does not contain any class names')\n",
    "         return\n",
    "\n",
    "     for directory in [train_path, test_path, val_path]:\n",
    "         for class_name in class_names:\n",
    "             (directory / class_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "     for class_name in class_names:\n",
    "\n",
    "         class_source_path = source_path / class_name\n",
    "\n",
    "         files = [f for f in class_source_path.iterdir() if f.is_file()]\n",
    "\n",
    "         random.shuffle(files)\n",
    "\n",
    "         total_files = len(files)\n",
    "         train_end = int(total_files * split_ratios[0])\n",
    "         test_end = train_end + int(total_files * split_ratios[1])\n",
    "\n",
    "         split_data = {\n",
    "             'train': (files[:train_end], train_path),\n",
    "             'test': (files[train_end:test_end], test_path),\n",
    "             'val': (files[test_end:], val_path)\n",
    "         }\n",
    "\n",
    "         print(f\"Copying {class_name} to {base_path}\")\n",
    "\n",
    "         for split_name, (file_list, destination_path) in split_data.items():\n",
    "\n",
    "             dest_class_path = destination_path / class_name\n",
    "\n",
    "             for file_path in tqdm(file_list, desc=f'Copying {split_name} files'):\n",
    "\n",
    "                 shutil.copy2(file_path, dest_class_path / file_path.name)\n",
    "\n",
    "         print(f'Copying {class_name} finished!')\n",
    "\n",
    "     print(\"Data splitting successful!\")\n"
   ],
   "id": "3f61bebddba66303",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T06:10:18.976739Z",
     "start_time": "2025-08-06T06:10:18.970736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from torchvision import datasets\n",
    "\n",
    "class CustomDataset(datasets.ImageFolder):\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        path, target = self.samples[index]\n",
    "\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "# data = CustomDataset(root='dataset', transform=training_pipeline)\n",
    "\n",
    "# image, path = data[0]\n",
    "#\n",
    "# print(path)\n",
    "#\n",
    "# image = image.permute(1,2,0).numpy()\n",
    "#\n",
    "# image = (image * np\n",
    "#          .array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n",
    "# image = np.clip(image, 0, 1)\n",
    "# image = (image * 255).astype(np.uint8)\n",
    "#\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ],
   "id": "4165f31c2a079958",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2> Data splitting </h2>",
   "id": "638f3a60c11f293c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T06:10:55.576968Z",
     "start_time": "2025-08-06T06:10:47.880042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source_data_dir = r'C:\\Users\\LANCE\\OneDrive\\Desktop\\rice_pest\\Finalized_datasets'\n",
    "base_data_dir = r'C:\\Users\\LANCE\\OneDrive\\Desktop\\rice_pest\\datasets'\n",
    "\n",
    "if not source_data_dir or not base_data_dir:\n",
    "    raise ValueError('Source and base data directory not found')\n",
    "\n",
    "prepare_image_datasets(source_data_dir, base_data_dir, split_ratios=(0.7, 0.2, 0.1))\n"
   ],
   "id": "407974787d3ba3a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying brown-planthopper to C:\\Users\\LANCE\\OneDrive\\Desktop\\rice_pest\\datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train files: 100%|██████████| 1712/1712 [00:01<00:00, 1459.60it/s]\n",
      "Copying test files: 100%|██████████| 489/489 [00:00<00:00, 1477.35it/s]\n",
      "Copying val files: 100%|██████████| 246/246 [00:00<00:00, 1469.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying brown-planthopper finished!\n",
      "Copying green-leafhopper to C:\\Users\\LANCE\\OneDrive\\Desktop\\rice_pest\\datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train files: 100%|██████████| 1493/1493 [00:01<00:00, 1456.70it/s]\n",
      "Copying test files: 100%|██████████| 426/426 [00:00<00:00, 1411.68it/s]\n",
      "Copying val files: 100%|██████████| 215/215 [00:00<00:00, 1433.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying green-leafhopper finished!\n",
      "Copying rice-black-bug to C:\\Users\\LANCE\\OneDrive\\Desktop\\rice_pest\\datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train files: 100%|██████████| 106/106 [00:00<00:00, 1261.92it/s]\n",
      "Copying test files: 100%|██████████| 30/30 [00:00<00:00, 1250.05it/s]\n",
      "Copying val files: 100%|██████████| 16/16 [00:00<00:00, 1333.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying rice-black-bug finished!\n",
      "Copying rice-leaf-folder to C:\\Users\\LANCE\\OneDrive\\Desktop\\rice_pest\\datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train files: 100%|██████████| 1917/1917 [00:01<00:00, 1418.95it/s]\n",
      "Copying test files: 100%|██████████| 548/548 [00:00<00:00, 1459.07it/s]\n",
      "Copying val files: 100%|██████████| 275/275 [00:00<00:00, 1487.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying rice-leaf-folder finished!\n",
      "Copying stem-borer to C:\\Users\\LANCE\\OneDrive\\Desktop\\rice_pest\\datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train files: 100%|██████████| 1371/1371 [00:00<00:00, 1435.16it/s]\n",
      "Copying test files: 100%|██████████| 391/391 [00:00<00:00, 1391.46it/s]\n",
      "Copying val files: 100%|██████████| 197/197 [00:00<00:00, 1492.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying stem-borer finished!\n",
      "Copying whorl-maggot to C:\\Users\\LANCE\\OneDrive\\Desktop\\rice_pest\\datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train files: 100%|██████████| 870/870 [00:00<00:00, 1518.32it/s]\n",
      "Copying test files: 100%|██████████| 248/248 [00:00<00:00, 1441.85it/s]\n",
      "Copying val files: 100%|██████████| 125/125 [00:00<00:00, 1404.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying whorl-maggot finished!\n",
      "Data splitting successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2> Training functions and hyperparameters</h2>",
   "id": "dba860140f2d1e9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T07:37:06.427312Z",
     "start_time": "2025-08-05T07:37:06.421048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class LSoftmax(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features, number_of_classes, m=4):\n",
    "        super(LSoftmax, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.number_of_classes = number_of_classes\n",
    "        self.m = m\n",
    "\n",
    "        if m <= 1:\n",
    "            raise ValueError('m must be greater than 1')\n",
    "\n",
    "        # Initialization of weights through xavier uniform.\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(input_features, number_of_classes))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    # Forward propagation\n",
    "    def forward(self, x, labels):\n",
    "\n",
    "        # normalization of weights and input vector features.\n",
    "        normalize_weight = F.normalize(self.weight, p=2, dim=1)\n",
    "        normalize_x = F.normalize(x, p=2, dim=1)\n",
    "\n",
    "        # Cosine similarity: perform DOT product multiplication between weights and input vectors.\n",
    "        cos_theta = F.linear(normalize_x, normalize_weight.t())\n",
    "        cos_theta = cos_theta.clamp(-1,1)\n",
    "\n",
    "        # Convert cosine similarity into actual angles.\n",
    "        theta = torch.acos(cos_theta)\n",
    "\n",
    "        # Gathered the correct classes as one vector and reshape it in to a 2d with one column.\n",
    "        target_theta = theta.gather(1, labels.view(-1,1))\n",
    "\n",
    "        # applies the margin to the correct classes\n",
    "        m_theta = self.m * target_theta\n",
    "        k = (m_theta / math.pi).floor()\n",
    "\n",
    "        # Compute the angular margin to get a new hard target score for prediction\n",
    "        psi_theta = ((-1)**k) * torch.cos(m_theta) - (2*k)\n",
    "\n",
    "        # Scattered the new values got from psi_theta to its corresponding classes\n",
    "        final_logits = cos_theta.scatter(1, labels.view(-1,1), psi_theta)\n",
    "\n",
    "        return final_logits\n"
   ],
   "id": "31a9a78b6df933f4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:20:24.301918Z",
     "start_time": "2025-08-05T16:20:24.297905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# t = torch.tensor([[1, 2, 3, 4],\n",
    "#                   [5,6,7,8]])\n",
    "#\n",
    "# t.gather(1, torch.tensor())\n",
    "\n",
    "t = torch.tensor([[1, 2, 3, 4],\n",
    "                  [5,6,7,8]])\n",
    "\n",
    "print(t.view(-1,2))"
   ],
   "id": "eec42032231e0ff9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3> LSmax Test </h3>",
   "id": "8abca27bc20b3b89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:13:28.962845Z",
     "start_time": "2025-08-03T14:13:28.957393Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the output logits: torch.Size([4, 6])\n",
      "\n",
      "Output Logits Tensor (first 2 rows):\n",
      "[[-2.2175212  -0.46530092  0.4388179  -0.13423419  0.6960334   0.20117837]\n",
      " [ 0.06377348  0.31151363  0.52479124  0.12865415 -3.1037827   0.04310565]]\n"
     ]
    }
   ],
   "execution_count": 277,
   "source": [
    "# NUM_FEATURES = 1280\n",
    "# NUM_CLASSES = 6\n",
    "# BATCH_SIZE = 4\n",
    "# MARGIN = 4\n",
    "#\n",
    "# lsoftmax_layer = LSoftmax(\n",
    "#     input_features=NUM_FEATURES,\n",
    "#     number_of_classes=NUM_CLASSES,\n",
    "#     m=MARGIN\n",
    "# )\n",
    "#\n",
    "# dummy_features = torch.randn(BATCH_SIZE, NUM_FEATURES)\n",
    "# dummy_labels = torch.randint(0, NUM_CLASSES, (BATCH_SIZE,))\n",
    "# res = lsoftmax_layer(dummy_features, dummy_labels)\n",
    "#\n",
    "# print(\"Shape of the output logits:\", res.shape)\n",
    "# print(\"\\nOutput Logits Tensor (first 2 rows):\")\n",
    "# print(res.detach().numpy()[:2])"
   ],
   "id": "42f054b187673f6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T07:37:12.411765Z",
     "start_time": "2025-08-05T07:37:12.404551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class PestClassifierMobileNetV2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, margin):\n",
    "        super(PestClassifierMobileNetV2, self).__init__()\n",
    "\n",
    "        # get model\n",
    "        self.base_model = models.mobilenet_v2(weights='MobileNet_V2_Weights.IMAGENET1K_V2')\n",
    "\n",
    "        # Froze feature extraction layer to retain weights.\n",
    "        for params in self.base_model.parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "        # get number of features\n",
    "        num_filters = self.base_model.classifier[1].in_features\n",
    "\n",
    "        # Hyperparameter tuning: Instantiate LSoftmax as new customized final layer.\n",
    "        self.base_model.classifier[1] = LSoftmax(\n",
    "            input_features=num_filters,\n",
    "            number_of_classes=num_classes,\n",
    "            m=margin\n",
    "        )\n",
    "\n",
    "    # Forward propagation\n",
    "    def forward(self, x, labels=None):\n",
    "\n",
    "        if labels is None:\n",
    "            return self.base_model(x)\n",
    "\n",
    "        # Passed the features in feature extraction layer.\n",
    "        features = self.base_model.features(x)\n",
    "\n",
    "        # Adaptive average pooling: returns a 2d scaled vector features.\n",
    "        features = F.adaptive_avg_pool2d(features, (1,1)).reshape(features.shape[0], -1)\n",
    "\n",
    "        # Implementation of the LSoftmax through passing the feature vectors for classification.\n",
    "        logits = self.base_model.classifier[1](features)\n",
    "\n",
    "        # return the result logits\n",
    "        return logits\n"
   ],
   "id": "ec3d396b8b938549",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T07:37:16.249455Z",
     "start_time": "2025-08-05T07:37:16.241546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_test(model, optimizer, criterion, train_dataloader, test_dataloader, num_epoch, device):\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    accuracies = []\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "\n",
    "        # Training phase\n",
    "        for data, labels in tqdm(train_dataloader, desc=f\"Train epoch: {epoch+1}\"):\n",
    "\n",
    "            data, target = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data, labels)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        training_loss = running_train_loss / len(train_dataloader)\n",
    "        train_losses.append(training_loss)\n",
    "\n",
    "        # Testing phase\n",
    "\n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for inputs, labels in tqdm(test_dataloader, desc=f\"Test epoch: {epoch+1}\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                output_loss = model(inputs, labels)\n",
    "                loss = criterion(output_loss, labels)\n",
    "                running_test_loss += loss.item()\n",
    "\n",
    "                output_predictions = model(inputs, labels=None)\n",
    "                _, predicted = torch.max(output_predictions.data, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "        testing_loss = running_test_loss / len(test_dataloader)\n",
    "        test_losses.append(testing_loss)\n",
    "        accuracy = 100 * correct_predictions / total_samples\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        epoch_summary = f'Epoch {epoch+1}/{num_epoch} | Train Loss: {training_loss} | Test Loss: {testing_loss} | Accuracy: {accuracy:.2f}%'\n",
    "\n",
    "        if device == 'cuda':\n",
    "            memory_mb = torch.cuda.memory_allocated() /(1024 ** 3)\n",
    "            epoch_summary += f'| GPU memory used: {memory_mb:.2f} GB'\n",
    "\n",
    "        print(epoch_summary)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), 'MobileNetV2_rice_pest_classification.pth')\n",
    "\n",
    "    print('Training done!')"
   ],
   "id": "ce2d84aa93514e4e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3> Data loader </h3>",
   "id": "dacf376c70e73e20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T07:37:19.487092Z",
     "start_time": "2025-08-05T07:37:19.431653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = CustomDataset(root='dataset/train', transform=training_pipeline)\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_set = CustomDataset(root='dataset/test', transform=validation_pipeline)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "\n",
    "classes = train_set.classes\n",
    "print(classes)\n"
   ],
   "id": "a1a36a79cb8fa3c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown-planthopper', 'green-leafhopper', 'rice-leaf-folder', 'stem-borer', 'whorl-maggot']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T00:36:15.237380Z",
     "start_time": "2025-08-05T00:36:15.228638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "hardware = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classes = 6\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-2\n",
    "num_margin = 4\n",
    "num_epochs = 24\n",
    "\n",
    "model = PestClassifierMobileNetV2(num_classes=classes, margin=num_margin).to(hardware)\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_and_test(model, optimizer, criterion, train_loader, test_loader, num_epochs, hardware)"
   ],
   "id": "8b86d7544f98ce59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def softmax_thresholding():\n",
    "\n"
   ],
   "id": "40c760dbbce2bb7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from PIL import Image\n",
    "\n",
    "def predict_single_image(model, image, classes, device):\n",
    "\n",
    "    model.load_state_dict(torch.load('MobileNetV2_rice_pest_classification.pth'))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    image = Image.open(image).convert('RGB')\n",
    "    image_tensor = validation_pipeline(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        result = model(image_tensor)\n",
    "        probability = F.softmax(result, dim=1)\n",
    "        confidence, predicted = torch.max(probability, 1)\n",
    "\n",
    "        predicted_class = classes[predicted.item()]\n",
    "        confidence_score = confidence.item()\n",
    "\n",
    "    return predicted_class, confidence_score\n"
   ],
   "id": "dee7cd10e5d47d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T06:58:05.606637Z",
     "start_time": "2025-08-04T06:58:05.536213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = models.mobilenet_v2(weights='MobileNet_V2_Weights.IMAGENET1K_V2')\n",
    "\n",
    "# print(model.classifier[1])\n",
    "print(model.features)"
   ],
   "id": "70fc048993a81d19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2dNormActivation(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (4): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (9): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (12): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (13): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (15): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (17): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (18): Conv2dNormActivation(\n",
      "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T11:12:56.503471Z",
     "start_time": "2025-08-04T11:12:56.468555Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.features[0])",
   "id": "addb634cef4616cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T04:37:03.301934Z",
     "start_time": "2025-08-04T04:37:03.274456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(4, 1280, 1, 1)\n",
    "a.reshape(4, -1)"
   ],
   "id": "27a5d55f61892fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6195, -0.1782, -2.5715,  ...,  0.0331,  0.7603,  0.0035],\n",
       "        [-0.2862,  1.4578,  1.0089,  ...,  1.1253,  0.0103,  1.5974],\n",
       "        [-0.3662,  2.0849, -0.4080,  ..., -0.4553, -1.3057, -0.6453],\n",
       "        [ 1.8317, -1.2072,  0.1279,  ..., -0.2502, -2.0353,  0.0071]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T03:04:36.935884Z",
     "start_time": "2025-08-04T03:04:36.928884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "m = nn.AdaptiveAvgPool2d((5, 7))\n",
    "input = torch.randn(1, 64, 8, 9)\n",
    "output = m(input)\n",
    "# print(input)\n",
    "print(output)"
   ],
   "id": "72bac0fc4c1c0861",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2691,  0.9643,  0.8347,  ..., -0.1645, -0.1972, -0.2539],\n",
      "          [ 0.2757,  0.9418,  0.9279,  ...,  0.5813,  0.1480, -0.1334],\n",
      "          [ 0.0424,  0.0234, -0.4845,  ...,  0.5998, -0.1160,  0.5142],\n",
      "          [ 0.4355,  0.0480, -0.6159,  ...,  0.0204, -0.6934, -0.3013],\n",
      "          [ 0.2712,  0.3419, -0.3261,  ..., -0.7096, -0.8251, -0.5811]],\n",
      "\n",
      "         [[ 0.5099, -0.4436, -0.1795,  ...,  0.9180,  0.1221, -0.5859],\n",
      "          [ 0.2151, -0.2515, -0.0462,  ...,  0.3873,  0.2008, -0.3096],\n",
      "          [-0.2853, -0.7343, -0.6029,  ...,  0.3461,  1.0835,  0.1555],\n",
      "          [-0.5955, -0.3730,  0.0737,  ...,  0.0337,  0.1940, -0.0271],\n",
      "          [-0.3843, -0.3897, -0.2840,  ..., -0.3347, -0.0284, -0.2131]],\n",
      "\n",
      "         [[ 0.2297,  0.6255,  0.5641,  ..., -0.9883, -1.5511, -0.7901],\n",
      "          [ 0.3697,  0.2164,  0.4150,  ..., -0.0471, -0.8920, -0.4873],\n",
      "          [ 0.2315,  0.2039,  0.3022,  ...,  0.9991,  0.1681,  0.1191],\n",
      "          [-0.1260,  0.3516,  0.5540,  ...,  0.0779, -0.3429, -0.2304],\n",
      "          [-0.5682,  0.1579, -0.0344,  ..., -0.0618, -0.2110,  0.1175]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6150,  0.6456, -0.2932,  ...,  0.8546,  0.7936,  0.1099],\n",
      "          [ 0.2835,  0.2893,  0.3964,  ...,  0.0333,  0.3866,  0.1173],\n",
      "          [ 0.1400, -0.5249,  0.4299,  ..., -0.2286,  0.0738, -0.7064],\n",
      "          [-0.0273, -0.6368,  0.0249,  ...,  0.5992,  0.4649, -0.7985],\n",
      "          [-0.1805, -0.5087, -0.4180,  ...,  0.1171,  0.1937, -0.6574]],\n",
      "\n",
      "         [[-0.5340, -0.5393, -0.1845,  ..., -0.3295, -0.2682, -0.9194],\n",
      "          [-0.7766, -0.6549, -0.3514,  ...,  0.3879,  0.0888, -0.5115],\n",
      "          [ 0.5817,  0.4015, -0.4562,  ...,  0.3205,  0.4115,  0.4215],\n",
      "          [ 0.1233, -0.1064, -0.2970,  ...,  0.5230,  0.6890,  0.1809],\n",
      "          [ 0.1536, -0.4041,  0.7407,  ..., -0.4805, -0.5290, -0.3725]],\n",
      "\n",
      "         [[-0.0880, -0.5350, -0.6104,  ..., -0.0955,  0.3950, -0.4115],\n",
      "          [-0.1270, -0.1667, -0.0691,  ...,  0.3164,  0.8346,  0.2359],\n",
      "          [-0.0628,  0.6373,  0.4045,  ...,  0.5000,  0.5107, -0.0409],\n",
      "          [-0.2748, -0.1589, -0.2421,  ...,  0.5904,  0.0789, -0.2165],\n",
      "          [-0.2584,  0.0901, -0.1130,  ..., -0.0214,  0.6294,  0.6648]]]])\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:29:01.468086Z",
     "start_time": "2025-08-05T13:29:01.432968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def say_hello():\n",
    "    \"\"\"First version of the function.\"\"\"\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the first version\n",
    "print(\"Calling the first version:\")\n",
    "say_hello()\n",
    "# Output: Hello, World!\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "def say_hello():\n",
    "    \"\"\"Second, 'overridden' version of the function.\"\"\"\n",
    "    print(\"¡Hola, Mundo!\")\n",
    "\n",
    "# Call the second version\n",
    "print(\"Calling the overridden version:\")\n",
    "say_hello()\n",
    "# Output: ¡Hola, Mundo!"
   ],
   "id": "4b239c3d1796a221",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling the first version:\n",
      "Hello, World!\n",
      "--------------------\n",
      "Calling the overridden version:\n",
      "¡Hola, Mundo!\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
