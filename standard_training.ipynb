{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:01:35.758152Z",
     "start_time": "2025-08-18T03:01:35.753962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "id": "cb5a725a97da07f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:01:36.450359Z",
     "start_time": "2025-08-18T03:01:36.445379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "allocated_bytes = torch.cuda.memory_allocated('cuda')\n",
    "allocated_mb = allocated_bytes / (1024 * 1024)\n",
    "\n",
    "reserved_bytes = torch.cuda.memory_reserved('cuda')\n",
    "reserved_mb = reserved_bytes / (1024 * 1024)\n",
    "\n",
    "print(\"\\n--- VRAM USAGE REPORT ---\")\n",
    "print(f\"Memory Allocated: {allocated_mb:.2f} MB\")\n",
    "print(f\"Memory Reserved:  {reserved_mb:.2f} MB\")\n",
    "print(\"-------------------------\\n\")"
   ],
   "id": "23d50c3f254a094",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- VRAM USAGE REPORT ---\n",
      "Memory Allocated: 0.00 MB\n",
      "Memory Reserved:  0.00 MB\n",
      "-------------------------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-18T03:01:37.098021Z",
     "start_time": "2025-08-18T03:01:37.063738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "`import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "training_pipeline = A.Compose([\n",
    "\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.RandomCrop(height=180, width=180, p=1.0),\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=45, p=0.4),\n",
    "\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=(-0.2, 0.2), p=0.4),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.4),\n",
    "\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(std_range=(0.1, 0.2), per_channel=True, p=0.4),\n",
    "        A.RandomRain(slant_range=(-15, 15), drop_length=15, drop_width=1, rain_type=\"default\", blur_value=7, p=0.4),\n",
    "        A.CoarseDropout(num_holes_range=(1, 3), hole_height_range=(0.1, 0.25), hole_width_range=(0.1, 0.25), fill=0, p=0.4)\n",
    "    ], p=0.5),\n",
    "\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "validation_pipeline = A.Compose([\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "basic_pipeline = A.Compose([\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.HorizontalFlip(p=0.6),\n",
    "    A.VerticalFlip(p=0.6),\n",
    "    A.Rotate(limit=(-45,45), p=0.7),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:01:40.085979Z",
     "start_time": "2025-08-18T03:01:38.620723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from torchvision import datasets\n",
    "\n",
    "class CustomDataset(datasets.ImageFolder):\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        path, target = self.samples[index]\n",
    "\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ],
   "id": "6daf511998047715",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:01:41.480040Z",
     "start_time": "2025-08-18T03:01:41.474188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "class PestClassifierMobileNetV2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(PestClassifierMobileNetV2, self).__init__()\n",
    "\n",
    "        # get model\n",
    "        self.base_model = models.mobilenet_v2(weights='MobileNet_V2_Weights.IMAGENET1K_V2')\n",
    "\n",
    "        # Froze feature extraction layer to retain weights.\n",
    "        for params in self.base_model.parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "        # get number of features\n",
    "        num_filters = self.base_model.classifier[1].in_features\n",
    "\n",
    "        # Hyperparameter tuning: new layer for 6 rice pests.\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(num_filters, num_classes),\n",
    "        )\n",
    "\n",
    "    # Forward propagation\n",
    "    def forward(self, x):\n",
    "\n",
    "       features = self.base_model.features(x)\n",
    "\n",
    "       features = F.adaptive_avg_pool2d(features, output_size=(1, 1)).reshape(features.shape[0], -1)\n",
    "\n",
    "       features = self.base_model.classifier(features)\n",
    "\n",
    "       return features\n",
    "\n",
    "    def unfreeze_feature_layer(self, layer):\n",
    "\n",
    "        if not (1 <= layer <= len(self.base_model.features)):\n",
    "            print(f\"Error: Invalid layer index {layer}.\")\n",
    "            return\n",
    "\n",
    "        # Corrected print statement\n",
    "        print(f\"\\nUnfreezing feature layer at index: -{layer}\")\n",
    "\n",
    "        for param in self.base_model.features[-layer].parameters():\n",
    "            param.requires_grad = True\n"
   ],
   "id": "8172f748d43e758a",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:01:43.332690Z",
     "start_time": "2025-08-18T03:01:43.326680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PestClassifierEfficientNetV2M(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(PestClassifierEfficientNetV2M, self).__init__()\n",
    "\n",
    "        self.base_model = models.efficientnet_v2_m(weights='EfficientNet_V2_M_Weights.IMAGENET1K_V1')\n",
    "\n",
    "        for params in self.base_model.parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "        features = self.base_model.classifier[1].in_features\n",
    "\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(features, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        features = self.base_model.features(x)\n",
    "\n",
    "        features = F.adaptive_avg_pool2d(features, output_size=(1, 1)).reshape(features.shape[0], -1)\n",
    "\n",
    "        features = self.base_model.classifier(features)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def unfreeze_feature_layer(self, layer):\n",
    "\n",
    "        if not (1 <= layer <= len(self.base_model.features)):\n",
    "            print(f\"Error: Invalid layer index {layer}.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nUnfreezing feature layer at index: -{layer}\")\n",
    "\n",
    "        for params in self.base_model.features[-layer].parameters():\n",
    "            params.requires_grad = True\n"
   ],
   "id": "2d2d688f4e97b8e2",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:01:45.552375Z",
     "start_time": "2025-08-18T03:01:45.542376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_and_test(model, optimizer, criterion, train_dataloader, test_dataloader, num_epoch, device, best_accuracy=0.0):\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        # --- TRAINING PHASE ---\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "\n",
    "        for data, labels in tqdm(train_dataloader, desc=f\"Train epoch: {epoch+1}\"):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        training_loss = running_train_loss / len(train_dataloader)\n",
    "        train_losses.append(training_loss)\n",
    "\n",
    "        # --- TESTING PHASE ---\n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for data, labels in tqdm(test_dataloader, desc=f\"Test epoch: {epoch+1}\"):\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                loss = criterion(output, labels)\n",
    "                running_test_loss += loss.item()\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "        testing_loss = running_test_loss / len(test_dataloader)\n",
    "        test_losses.append(testing_loss)\n",
    "        accuracy = 100 * correct_predictions / total_samples\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        epoch_summary = f'Epoch {epoch+1}/{num_epoch} | Train Loss: {training_loss:.4f} | Test Loss: {testing_loss:.4f} | Accuracy: {accuracy:.2f}%'\n",
    "\n",
    "        if device.type == 'cuda':\n",
    "            allocated_gb = torch.cuda.memory_allocated() / (1024 ** 3)\n",
    "            reserved_gb = torch.cuda.memory_reserved() / (1024 ** 3)\n",
    "            epoch_summary += f' | GPU Memory (Alloc/Reserved): {allocated_gb:.3f}/{reserved_gb:.3f} GB'\n",
    "\n",
    "        tqdm.write(epoch_summary)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), 'models/MobileNetV2/v2/Basic/SMobileNetV2_rice_pest_classificationV13.pt')\n",
    "\n",
    "        # scheduler.step(testing_loss)\n",
    "\n",
    "    tqdm.write('Phase done!')\n",
    "\n",
    "    return {'train_loss': train_losses, 'test_loss': test_losses, 'accuracy': accuracies}, best_accuracy"
   ],
   "id": "fca4e6f7abec2fbd",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>  Saving and plott</h2>",
   "id": "9b5134a74e091e48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:04:39.434138Z",
     "start_time": "2025-08-18T03:04:39.424710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def plot_training_result(*results):\n",
    "\n",
    "    full_training_loss = []\n",
    "    full_test_loss = []\n",
    "\n",
    "    for result in results:\n",
    "        train_loss = result.get('train_loss', [])\n",
    "        full_training_loss.extend(train_loss)\n",
    "        full_test_loss.extend(result.get('test_loss', []))\n",
    "\n",
    "    total_epochs = len(full_training_loss)\n",
    "\n",
    "    if total_epochs == 0:\n",
    "        print(\"No data to plot.\")\n",
    "        return\n",
    "\n",
    "    epochs = range(1, total_epochs + 1)\n",
    "\n",
    "    data = {\n",
    "        'Epoch': epochs,\n",
    "        'Training Loss': full_training_loss,\n",
    "        'Testing Loss': full_test_loss,\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df_long = df.melt(id_vars=['Epoch'], var_name='Loss Type', value_name='Loss')\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long, x='Epoch', y='Loss', hue='Loss Type', marker='o')\n",
    "\n",
    "    plt.title('Training and Testing Loss Comparison')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(*results):\n",
    "\n",
    "    full_accuracy = []\n",
    "\n",
    "    for res in results:\n",
    "        accuracy = res.get('accuracy', [])\n",
    "        full_accuracy.extend(accuracy)\n",
    "\n",
    "    total_epochs = len(full_accuracy)\n",
    "\n",
    "    if total_epochs == 0:\n",
    "        print(\"No accuracy data to plot.\")\n",
    "        return\n",
    "\n",
    "    epochs = range(1, total_epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(epochs, full_accuracy, label='Accuracy', marker='o', color='g')\n",
    "\n",
    "    plt.title('Accuracy Evaluation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def accuracy_per_session(session_accuracies):\n",
    "\n",
    "    total_sessions = len(session_accuracies)\n",
    "    if total_sessions == 0: return\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, total_sessions + 1), session_accuracies, label='Best Session Accuracy', marker='o', color='r')\n",
    "    plt.title('Best Accuracy per Training Session')\n",
    "    plt.xlabel('Training Session')\n",
    "    plt.ylabel('Best Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def save_historical_data(history, filename='training_results/v2/SMobileNetV2_rice_pest_classificationV13.csv'):\n",
    "\n",
    "    train_loss = history.get('train_loss', [])\n",
    "    test_loss = history.get('test_loss', [])\n",
    "    accuracy = history.get('accuracy', [])\n",
    "\n",
    "    data_dict = pd.DataFrame({\n",
    "        'train_loss': train_loss,\n",
    "        'test_loss': test_loss,\n",
    "        'accuracy': accuracy,\n",
    "    })\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        print(\"historical data exists! Appending new data.\")\n",
    "\n",
    "        old_data = pd.read_csv(filename)\n",
    "        combined_data = pd.concat([old_data, data_dict], ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        print(\"Creating new historical data...\")\n",
    "        combined_data = data_dict\n",
    "\n",
    "    combined_data['epoch'] = range(1, len(combined_data) + 1)\n",
    "\n",
    "    combined_data = combined_data[['epoch', 'train_loss', 'test_loss', 'accuracy']]\n",
    "\n",
    "    combined_data.to_csv(filename, index=False)\n",
    "\n",
    "    print(\"Historical data saved successfully!\")\n"
   ],
   "id": "74773810c269080d",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:04:42.211268Z",
     "start_time": "2025-08-18T03:04:42.065191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = CustomDataset(root='datasets/train', transform=training_pipeline)\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_set = CustomDataset(root='datasets/test', transform=validation_pipeline)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "val_set = CustomDataset(root='datasets/val', transform=validation_pipeline)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "\n",
    "classes = train_set.classes"
   ],
   "id": "4fd20dd312f838ff",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:08:29.168046Z",
     "start_time": "2025-08-18T03:08:29.163185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def incremental_training(model, sessions, criterion, train_dataloader, test_dataloader, device):\n",
    "\n",
    "    full_history = []\n",
    "    session_best_accuracies = []\n",
    "    best_overall_accuracy = 0.0\n",
    "\n",
    "    for i, session in enumerate(sessions):\n",
    "        print(f\"\\n--- Starting Training Session {i+1}/{len(sessions)} ---\")\n",
    "\n",
    "        epochs = session['epochs']\n",
    "        lr = session['lr']\n",
    "        layer_to_unfreeze = session.get('unfreeze_layer', 0)\n",
    "\n",
    "        if layer_to_unfreeze > 0:\n",
    "            model.unfreeze_feature_layer(layer_to_unfreeze)\n",
    "\n",
    "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "        session_history, best_overall_accuracy = train_and_test(\n",
    "            model, optimizer, criterion, train_dataloader, test_dataloader, epochs, device, best_accuracy=best_overall_accuracy\n",
    "        )\n",
    "\n",
    "        full_history.append(session_history)\n",
    "\n",
    "        save_historical_data(session_history)\n",
    "\n",
    "        if session_history['accuracy']:\n",
    "            best_in_session = max(session_history['accuracy'])\n",
    "            session_best_accuracies.append(best_in_session)\n",
    "\n",
    "    return full_history, session_best_accuracies"
   ],
   "id": "1467cef09840c64b",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:08:45.346631Z",
     "start_time": "2025-08-18T03:08:43.759392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "hardware = torch.device('cuda' if  torch.cuda.is_available() else 'cpu')\n",
    "classes = 6\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-2\n",
    "num_epochs = 32\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = PestClassifierMobileNetV2(num_classes=classes).to(hardware)\n",
    "\n",
    "training_sessions = [\n",
    "    {'epochs': 15, 'lr': 1e-4, 'unfreeze_layer': 0},\n",
    "    {'epochs': 30, 'lr': 1e-4, 'unfreeze_layer': 1},\n",
    "    {'epochs': 45, 'lr': 1e-4, 'unfreeze_layer': 2},\n",
    "]\n",
    "\n",
    "result, accuracies = incremental_training(model=model, sessions=training_sessions, criterion=criterion, train_dataloader=train_loader, test_dataloader=test_loader, device=hardware)\n",
    "\n",
    "accuracy_per_session(accuracies)\n",
    "plot_training_result(*result)\n",
    "plot_accuracy(*result)"
   ],
   "id": "fd1ee3a6a8b445e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training Session 1/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 1:   0%|          | 0/59 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[42]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[32m     10\u001B[39m model = PestClassifierMobileNetV2(num_classes=classes).to(hardware)\n\u001B[32m     12\u001B[39m training_sessions = [\n\u001B[32m     13\u001B[39m     {\u001B[33m'\u001B[39m\u001B[33mepochs\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m15\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mlr\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m1e-4\u001B[39m, \u001B[33m'\u001B[39m\u001B[33munfreeze_layer\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m0\u001B[39m},\n\u001B[32m     14\u001B[39m     {\u001B[33m'\u001B[39m\u001B[33mepochs\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m30\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mlr\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m1e-4\u001B[39m, \u001B[33m'\u001B[39m\u001B[33munfreeze_layer\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m1\u001B[39m},\n\u001B[32m     15\u001B[39m     {\u001B[33m'\u001B[39m\u001B[33mepochs\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m45\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mlr\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m1e-4\u001B[39m, \u001B[33m'\u001B[39m\u001B[33munfreeze_layer\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m2\u001B[39m},\n\u001B[32m     16\u001B[39m ]\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m result, accuracies = \u001B[43mincremental_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msessions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtraining_sessions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhardware\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m accuracy_per_session(accuracies)\n\u001B[32m     21\u001B[39m plot_training_result(*result)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[41]\u001B[39m\u001B[32m, line 19\u001B[39m, in \u001B[36mincremental_training\u001B[39m\u001B[34m(model, sessions, criterion, train_dataloader, test_dataloader, device)\u001B[39m\n\u001B[32m     15\u001B[39m     model.unfreeze_feature_layer(layer_to_unfreeze)\n\u001B[32m     17\u001B[39m optimizer = optim.AdamW(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m p: p.requires_grad, model.parameters()), lr=lr, weight_decay=\u001B[32m1e-2\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m session_history, best_overall_accuracy = \u001B[43mtrain_and_test\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbest_accuracy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbest_overall_accuracy\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m full_history.append(session_history)\n\u001B[32m     25\u001B[39m save_historical_data(session_history)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[37]\u001B[39m\u001B[32m, line 19\u001B[39m, in \u001B[36mtrain_and_test\u001B[39m\u001B[34m(model, optimizer, criterion, train_dataloader, test_dataloader, num_epoch, device, best_accuracy)\u001B[39m\n\u001B[32m     17\u001B[39m data, labels = data.to(device), labels.to(device)\n\u001B[32m     18\u001B[39m optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m output = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m loss = criterion(output, labels)\n\u001B[32m     21\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\rice_pest\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\rice_pest\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[35]\u001B[39m\u001B[32m, line 30\u001B[39m, in \u001B[36mPestClassifierMobileNetV2.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m     28\u001B[39m    features = \u001B[38;5;28mself\u001B[39m.base_model.features(x)\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m    features = \u001B[43mF\u001B[49m.adaptive_avg_pool2d(features, output_size=(\u001B[32m1\u001B[39m, \u001B[32m1\u001B[39m)).reshape(features.shape[\u001B[32m0\u001B[39m], -\u001B[32m1\u001B[39m)\n\u001B[32m     32\u001B[39m    features = \u001B[38;5;28mself\u001B[39m.base_model.classifier(features)\n\u001B[32m     34\u001B[39m    \u001B[38;5;28;01mreturn\u001B[39;00m features\n",
      "\u001B[31mNameError\u001B[39m: name 'F' is not defined"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T07:15:34.499960Z",
     "start_time": "2025-08-14T07:15:34.496483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# mobilenet_v2 = models.mobilenet_v2(weights='MobileNet_V2_Weights.IMAGENET1K_V2')\n",
    "#\n",
    "# for num in range(len(mobilenet_v2.features) - 1, -1, -1):\n",
    "#     print(num)\n",
    "\n",
    "my_array = [1, 2, 3, 4, 5]\n",
    "\n",
    "# print(my_array[-5])\n",
    "\n",
    "for num in range(1, my_array.__len__() + 1):\n",
    "    print(num)"
   ],
   "id": "f0d4ce6fa4b92ee4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "execution_count": 261
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:08:51.198984Z",
     "start_time": "2025-08-18T03:08:51.193917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_single_image(model, image_path, classes, transform, device):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    augmented = transform(image=image_np)\n",
    "\n",
    "    image_tensor = augmented['image'].unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        result = model(image_tensor)\n",
    "\n",
    "        probabilities = F.softmax(result, dim=1)\n",
    "\n",
    "        confidence, predicted_index = torch.max(probabilities, 1)\n",
    "        predicted_class = classes[predicted_index.item()]\n",
    "        confidence_score = confidence.item()\n",
    "\n",
    "    return predicted_class, confidence_score, probabilities.squeeze().cpu().numpy()\n"
   ],
   "id": "340b828c2f1ea908",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T03:08:54.130666Z",
     "start_time": "2025-08-18T03:08:53.878851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def eval_metrics(model, testLoader, classes_names, device):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for input, labels in tqdm(testLoader):\n",
    "            input, labels = input.to(device), labels.to(device)\n",
    "\n",
    "            output = model(input)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "            total_predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_true = np.array(true_labels)\n",
    "    y_pred = np.array(total_predictions)\n",
    "\n",
    "    print('Classification Report')\n",
    "    report = classification_report(y_true, y_pred, target_names=classes_names)\n",
    "\n",
    "    print(report)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)*100:.2f}%\\n\")\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    cm_df = pd.DataFrame(matrix, index=classes_names, columns=classes_names)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.title('Confusion Matrix (standard)')\n",
    "    plt.ylabel('Actual pests')\n",
    "    plt.xlabel('Predicted pests')\n",
    "    plt.show()\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def save_evalution_result(total_predictions, true_labels):\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'True Labels': true_labels,\n",
    "        'Predicted Labels': total_predictions\n",
    "    })\n",
    "\n",
    "    data.to_csv('evalution_result.csv', index=False)\n"
   ],
   "id": "3fb753e351ad7371",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T07:38:15.732275Z",
     "start_time": "2025-08-17T07:38:15.441516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "classes_names = train_set.classes\n",
    "hardware = torch.device('cuda' if   torch.cuda.is_available() else 'cpu')\n",
    "model_inference = PestClassifierMobileNetV2(num_classes=len(classes_names))\n",
    "model_inference.load_state_dict(torch.load('models/MobileNetV2/v2/Basic/SMobileNetV2_rice_pest_classificationV13.pt', map_location=hardware))\n",
    "image_path = 'datasets/val/rice-black-bug/blackbug5_jpg.rf.424e09d72d12102f5c45f11cebd47d70.jpg'\n",
    "unrelated = 'unrelated_data/images.jpg'\n",
    "\n",
    "pest, confidence_score, over_all_scores = predict_single_image(model=model_inference, image_path=image_path, classes=classes_names, transform=validation_pipeline, device=hardware)\n",
    "\n",
    "print(f\"The predicted pest is: {pest}\")\n",
    "print(f\"Confidence: {confidence_score * 100:.2f}%\")\n",
    "print(f\"Overall score: {over_all_scores}\")\n",
    "#\n",
    "# true, pred = eval_metrics(model_inference, val_loader, classes_names, hardware)"
   ],
   "id": "affbac0d0a0851c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted pest is: rice-black-bug\n",
      "Confidence: 94.00%\n",
      "Overall score: [5.5456121e-02 3.5791690e-03 9.4000769e-01 2.6055515e-05 9.0353707e-05\n",
      " 8.4059639e-04]\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
